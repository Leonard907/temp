{'padding_count': 0, 'loss': 5.5339, 'learning_rate': 1.0434782608695651e-05, 'epoch': 0.09}
{'padding_count': 0, 'loss': 4.3767, 'learning_rate': 2.782608695652174e-05, 'epoch': 0.17}
{'padding_count': 0, 'loss': 4.2213, 'learning_rate': 4.521739130434783e-05, 'epoch': 0.26}
{'padding_count': 0, 'loss': 3.9818, 'learning_rate': 6.260869565217392e-05, 'epoch': 0.35}
{'padding_count': 0, 'loss': 3.9024, 'learning_rate': 8e-05, 'epoch': 0.43}
{'padding_count': 0, 'loss': 3.8944, 'learning_rate': 9.739130434782609e-05, 'epoch': 0.52}
{'padding_count': 0, 'loss': 3.8279, 'learning_rate': 0.00011478260869565218, 'epoch': 0.61}
{'padding_count': 0, 'loss': 3.7115, 'learning_rate': 0.00013217391304347825, 'epoch': 0.7}
{'padding_count': 0, 'loss': 3.781, 'learning_rate': 0.00014956521739130436, 'epoch': 0.78}
{'padding_count': 0, 'loss': 3.8162, 'learning_rate': 0.00016521739130434784, 'epoch': 0.87}
{'padding_count': 0, 'loss': 3.7736, 'learning_rate': 0.00018260869565217392, 'epoch': 0.96}
{'eval_loss': 3.4992337226867676, 'eval_runtime': 1.8882, 'eval_samples_per_second': 179.006, 'eval_steps_per_second': 4.766, 'epoch': 1.0}
{'padding_count': 0, 'loss': 3.887, 'learning_rate': 0.0002, 'epoch': 1.04}
{'padding_count': 0, 'loss': 3.7865, 'learning_rate': 0.00019806763285024154, 'epoch': 1.13}
{'padding_count': 0, 'loss': 3.6743, 'learning_rate': 0.0001961352657004831, 'epoch': 1.22}
{'padding_count': 0, 'loss': 3.5703, 'learning_rate': 0.00019420289855072464, 'epoch': 1.3}
{'padding_count': 0, 'loss': 3.627, 'learning_rate': 0.0001922705314009662, 'epoch': 1.39}
{'padding_count': 0, 'loss': 3.4147, 'learning_rate': 0.00019033816425120773, 'epoch': 1.48}
{'padding_count': 0, 'loss': 3.4794, 'learning_rate': 0.00018840579710144927, 'epoch': 1.57}
{'padding_count': 0, 'loss': 3.4124, 'learning_rate': 0.00018647342995169083, 'epoch': 1.65}
{'padding_count': 0, 'loss': 3.3012, 'learning_rate': 0.00018454106280193236, 'epoch': 1.74}
{'padding_count': 0, 'loss': 3.4338, 'learning_rate': 0.00018260869565217392, 'epoch': 1.83}
{'padding_count': 0, 'loss': 3.3095, 'learning_rate': 0.00018067632850241546, 'epoch': 1.91}
{'padding_count': 0, 'loss': 3.4759, 'learning_rate': 0.00017874396135265702, 'epoch': 2.0}
{'eval_loss': 3.4167087078094482, 'eval_runtime': 1.901, 'eval_samples_per_second': 177.804, 'eval_steps_per_second': 4.734, 'epoch': 2.0}
{'padding_count': 0, 'loss': 3.4017, 'learning_rate': 0.00017681159420289858, 'epoch': 2.09}
{'padding_count': 0, 'loss': 3.2507, 'learning_rate': 0.00017487922705314011, 'epoch': 2.17}
{'padding_count': 0, 'loss': 3.2052, 'learning_rate': 0.00017294685990338165, 'epoch': 2.26}
{'padding_count': 0, 'loss': 3.2113, 'learning_rate': 0.0001710144927536232, 'epoch': 2.35}
{'padding_count': 0, 'loss': 3.0445, 'learning_rate': 0.00016908212560386474, 'epoch': 2.43}
{'padding_count': 0, 'loss': 3.2011, 'learning_rate': 0.0001671497584541063, 'epoch': 2.52}
{'padding_count': 0, 'loss': 3.0615, 'learning_rate': 0.00016521739130434784, 'epoch': 2.61}
{'padding_count': 0, 'loss': 2.9317, 'learning_rate': 0.00016328502415458937, 'epoch': 2.7}
{'padding_count': 0, 'loss': 3.0482, 'learning_rate': 0.00016135265700483093, 'epoch': 2.78}
{'padding_count': 0, 'loss': 3.0602, 'learning_rate': 0.00015942028985507247, 'epoch': 2.87}
{'padding_count': 0, 'loss': 3.0617, 'learning_rate': 0.00015748792270531403, 'epoch': 2.96}
{'eval_loss': 3.3886401653289795, 'eval_runtime': 1.8839, 'eval_samples_per_second': 179.41, 'eval_steps_per_second': 4.777, 'epoch': 3.0}
{'padding_count': 0, 'loss': 3.2055, 'learning_rate': 0.00015555555555555556, 'epoch': 3.04}
{'padding_count': 0, 'loss': 3.1492, 'learning_rate': 0.0001536231884057971, 'epoch': 3.13}
{'padding_count': 0, 'loss': 2.8037, 'learning_rate': 0.00015169082125603866, 'epoch': 3.22}
{'padding_count': 0, 'loss': 2.8858, 'learning_rate': 0.0001497584541062802, 'epoch': 3.3}
{'padding_count': 0, 'loss': 2.9316, 'learning_rate': 0.00014782608695652173, 'epoch': 3.39}
{'padding_count': 0, 'loss': 2.7685, 'learning_rate': 0.0001458937198067633, 'epoch': 3.48}
{'padding_count': 0, 'loss': 2.8319, 'learning_rate': 0.00014396135265700482, 'epoch': 3.57}
{'padding_count': 0, 'loss': 2.8303, 'learning_rate': 0.00014202898550724638, 'epoch': 3.65}
{'padding_count': 0, 'loss': 2.724, 'learning_rate': 0.00014009661835748792, 'epoch': 3.74}
{'padding_count': 0, 'loss': 2.8586, 'learning_rate': 0.00013816425120772948, 'epoch': 3.83}
{'padding_count': 0, 'loss': 2.7411, 'learning_rate': 0.00013623188405797104, 'epoch': 3.91}
{'padding_count': 0, 'loss': 3.0012, 'learning_rate': 0.00013429951690821257, 'epoch': 4.0}
{'eval_loss': 3.3885295391082764, 'eval_runtime': 1.8995, 'eval_samples_per_second': 177.94, 'eval_steps_per_second': 4.738, 'epoch': 4.0}
{'padding_count': 0, 'loss': 2.9153, 'learning_rate': 0.00013236714975845413, 'epoch': 4.09}
{'padding_count': 0, 'loss': 2.7079, 'learning_rate': 0.00013043478260869567, 'epoch': 4.17}
{'padding_count': 0, 'loss': 2.6103, 'learning_rate': 0.0001285024154589372, 'epoch': 4.26}
{'padding_count': 0, 'loss': 2.6711, 'learning_rate': 0.00012657004830917876, 'epoch': 4.35}
{'padding_count': 0, 'loss': 2.5223, 'learning_rate': 0.0001246376811594203, 'epoch': 4.43}
{'padding_count': 0, 'loss': 2.7611, 'learning_rate': 0.00012270531400966183, 'epoch': 4.52}
{'padding_count': 0, 'loss': 2.5552, 'learning_rate': 0.00012077294685990339, 'epoch': 4.61}
{'padding_count': 0, 'loss': 2.4964, 'learning_rate': 0.00011884057971014493, 'epoch': 4.7}
{'padding_count': 0, 'loss': 2.6134, 'learning_rate': 0.00011690821256038649, 'epoch': 4.78}
{'padding_count': 0, 'loss': 2.5731, 'learning_rate': 0.00011497584541062802, 'epoch': 4.87}
{'padding_count': 0, 'loss': 2.6578, 'learning_rate': 0.00011304347826086956, 'epoch': 4.96}
{'eval_loss': 3.4285881519317627, 'eval_runtime': 1.9543, 'eval_samples_per_second': 172.948, 'eval_steps_per_second': 4.605, 'epoch': 5.0}
{'padding_count': 0, 'loss': 2.7857, 'learning_rate': 0.00011111111111111112, 'epoch': 5.04}
{'padding_count': 0, 'loss': 2.7212, 'learning_rate': 0.00010917874396135266, 'epoch': 5.13}
{'padding_count': 0, 'loss': 2.2734, 'learning_rate': 0.00010724637681159421, 'epoch': 5.22}
{'padding_count': 0, 'loss': 2.4832, 'learning_rate': 0.00010531400966183576, 'epoch': 5.3}
{'padding_count': 0, 'loss': 2.5181, 'learning_rate': 0.00010338164251207729, 'epoch': 5.39}
{'padding_count': 0, 'loss': 2.3413, 'learning_rate': 0.00010144927536231885, 'epoch': 5.48}
{'padding_count': 0, 'loss': 2.428, 'learning_rate': 9.951690821256039e-05, 'epoch': 5.57}
{'padding_count': 0, 'loss': 2.4782, 'learning_rate': 9.758454106280194e-05, 'epoch': 5.65}
{'padding_count': 0, 'loss': 2.3124, 'learning_rate': 9.565217391304348e-05, 'epoch': 5.74}
{'padding_count': 0, 'loss': 2.4398, 'learning_rate': 9.371980676328503e-05, 'epoch': 5.83}
{'padding_count': 0, 'loss': 2.2916, 'learning_rate': 9.178743961352657e-05, 'epoch': 5.91}
{'padding_count': 0, 'loss': 2.6691, 'learning_rate': 8.985507246376813e-05, 'epoch': 6.0}
{'eval_loss': 3.4623899459838867, 'eval_runtime': 1.8978, 'eval_samples_per_second': 178.105, 'eval_steps_per_second': 4.742, 'epoch': 6.0}
{'padding_count': 0, 'loss': 2.5816, 'learning_rate': 8.792270531400967e-05, 'epoch': 6.09}
{'padding_count': 0, 'loss': 2.3346, 'learning_rate': 8.599033816425122e-05, 'epoch': 6.17}
{'padding_count': 0, 'loss': 2.2702, 'learning_rate': 8.405797101449276e-05, 'epoch': 6.26}
{'padding_count': 0, 'loss': 2.2849, 'learning_rate': 8.21256038647343e-05, 'epoch': 6.35}
{'padding_count': 0, 'loss': 2.1282, 'learning_rate': 8.019323671497585e-05, 'epoch': 6.43}
{'padding_count': 0, 'loss': 2.4273, 'learning_rate': 7.82608695652174e-05, 'epoch': 6.52}
{'padding_count': 0, 'loss': 2.1946, 'learning_rate': 7.632850241545893e-05, 'epoch': 6.61}
{'padding_count': 0, 'loss': 2.19, 'learning_rate': 7.439613526570048e-05, 'epoch': 6.7}
{'padding_count': 0, 'loss': 2.2801, 'learning_rate': 7.246376811594203e-05, 'epoch': 6.78}
{'padding_count': 0, 'loss': 2.1786, 'learning_rate': 7.053140096618357e-05, 'epoch': 6.87}
{'padding_count': 0, 'loss': 2.3085, 'learning_rate': 6.859903381642512e-05, 'epoch': 6.96}
{'eval_loss': 3.4952523708343506, 'eval_runtime': 1.8754, 'eval_samples_per_second': 180.228, 'eval_steps_per_second': 4.799, 'epoch': 7.0}
{'padding_count': 0, 'loss': 2.5024, 'learning_rate': 6.666666666666667e-05, 'epoch': 7.04}
{'padding_count': 0, 'loss': 2.4321, 'learning_rate': 6.473429951690822e-05, 'epoch': 7.13}
{'padding_count': 0, 'loss': 1.949, 'learning_rate': 6.280193236714976e-05, 'epoch': 7.22}
{'padding_count': 0, 'loss': 2.1575, 'learning_rate': 6.086956521739131e-05, 'epoch': 7.3}
{'padding_count': 0, 'loss': 2.2073, 'learning_rate': 5.8937198067632847e-05, 'epoch': 7.39}
{'padding_count': 0, 'loss': 2.0427, 'learning_rate': 5.7004830917874394e-05, 'epoch': 7.48}
{'padding_count': 0, 'loss': 2.12, 'learning_rate': 5.507246376811594e-05, 'epoch': 7.57}
{'padding_count': 0, 'loss': 2.2064, 'learning_rate': 5.3140096618357496e-05, 'epoch': 7.65}
{'padding_count': 0, 'loss': 2.0517, 'learning_rate': 5.1207729468599044e-05, 'epoch': 7.74}
{'padding_count': 0, 'loss': 2.1503, 'learning_rate': 4.9275362318840584e-05, 'epoch': 7.83}
{'padding_count': 0, 'loss': 1.9721, 'learning_rate': 4.7342995169082125e-05, 'epoch': 7.91}
{'padding_count': 0, 'loss': 2.3982, 'learning_rate': 4.541062801932367e-05, 'epoch': 8.0}
{'eval_loss': 3.540332317352295, 'eval_runtime': 1.871, 'eval_samples_per_second': 180.649, 'eval_steps_per_second': 4.81, 'epoch': 8.0}
{'padding_count': 0, 'loss': 2.3359, 'learning_rate': 4.347826086956522e-05, 'epoch': 8.09}
{'padding_count': 0, 'loss': 2.0352, 'learning_rate': 4.154589371980677e-05, 'epoch': 8.17}
{'padding_count': 0, 'loss': 2.0472, 'learning_rate': 3.961352657004831e-05, 'epoch': 8.26}
{'padding_count': 0, 'loss': 2.0398, 'learning_rate': 3.7681159420289856e-05, 'epoch': 8.35}
{'padding_count': 0, 'loss': 1.8534, 'learning_rate': 3.57487922705314e-05, 'epoch': 8.43}
{'padding_count': 0, 'loss': 2.2023, 'learning_rate': 3.381642512077295e-05, 'epoch': 8.52}
{'padding_count': 0, 'loss': 1.9345, 'learning_rate': 3.188405797101449e-05, 'epoch': 8.61}
{'padding_count': 0, 'loss': 1.9621, 'learning_rate': 2.995169082125604e-05, 'epoch': 8.7}
{'padding_count': 0, 'loss': 2.0606, 'learning_rate': 2.8019323671497587e-05, 'epoch': 8.78}
{'padding_count': 0, 'loss': 1.9422, 'learning_rate': 2.608695652173913e-05, 'epoch': 8.87}
{'padding_count': 0, 'loss': 2.1055, 'learning_rate': 2.4154589371980676e-05, 'epoch': 8.96}
{'eval_loss': 3.554307460784912, 'eval_runtime': 1.815, 'eval_samples_per_second': 186.221, 'eval_steps_per_second': 4.959, 'epoch': 9.0}
{'padding_count': 0, 'loss': 2.2953, 'learning_rate': 2.2222222222222223e-05, 'epoch': 9.04}
{'padding_count': 0, 'loss': 2.231, 'learning_rate': 2.028985507246377e-05, 'epoch': 9.13}
{'padding_count': 0, 'loss': 1.7503, 'learning_rate': 1.8357487922705315e-05, 'epoch': 9.22}
{'padding_count': 0, 'loss': 1.9648, 'learning_rate': 1.6425120772946863e-05, 'epoch': 9.3}
{'padding_count': 0, 'loss': 2.0078, 'learning_rate': 1.4492753623188407e-05, 'epoch': 9.39}
{'padding_count': 0, 'loss': 1.8324, 'learning_rate': 1.2560386473429953e-05, 'epoch': 9.48}
{'padding_count': 0, 'loss': 1.9229, 'learning_rate': 1.0628019323671499e-05, 'epoch': 9.57}
{'padding_count': 0, 'loss': 2.0225, 'learning_rate': 8.695652173913044e-06, 'epoch': 9.65}
{'padding_count': 0, 'loss': 1.8801, 'learning_rate': 6.7632850241545894e-06, 'epoch': 9.74}
{'padding_count': 0, 'loss': 1.9787, 'learning_rate': 4.830917874396135e-06, 'epoch': 9.83}
{'padding_count': 0, 'loss': 1.7892, 'learning_rate': 2.898550724637681e-06, 'epoch': 9.91}
{'padding_count': 0, 'loss': 2.2657, 'learning_rate': 9.66183574879227e-07, 'epoch': 10.0}
{'eval_loss': 3.590191125869751, 'eval_runtime': 1.9046, 'eval_samples_per_second': 177.464, 'eval_steps_per_second': 4.725, 'epoch': 10.0}
{'train_runtime': 2026.5186, 'train_samples_per_second': 18.125, 'train_steps_per_second': 0.567, 'train_loss': 2.7222198370228643, 'epoch': 10.0}
***** train metrics *****
  epoch                    =       10.0
  train_loss               =     2.7222
  train_runtime            = 0:33:46.51
  train_samples            =       3673
  train_samples_per_second =     18.125
  train_steps_per_second   =      0.567
***** eval metrics *****
  epoch                   =       10.0
  eval_loss               =     3.5902
  eval_runtime            = 0:00:01.81
  eval_samples            =        338
  eval_samples_per_second =    185.944
  eval_steps_per_second   =      4.951
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
[34m[1mwandb[39m[22m: [33mWARNING[39m Saving files without folders. If you want to preserve sub directories pass base_path to wandb.save, i.e. wandb.save("/mnt/folder/file.h5", base_path="/mnt")
  0%|                                                                                                    | 0/1150 [00:00<?, ?it/s][INFO|trainer.py:1411] 2022-06-09 15:41:55,007 >> Unused parameters:
/home/s1970716/miniconda3/envs/scrolls_venv/lib/python3.8/site-packages/transformers/trainer.py:1444: FutureWarning:
Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.
  0%|                                                                                          | 1/1150 [00:05<1:36:08,  5.02s/it]2022-06-09 15:41:55 | INFO | root | Reducer buckets have been rebuilt in this iteration.
 10%|█████████                                                                                 | 115/1150 [02:37<23:45,  1.38s/it][INFO|trainer.py:528] 2022-06-09 15:44:28,088 >> The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: not_valid_for_eval, length.
[INFO|trainer.py:2324] 2022-06-09 15:44:28,094 >> ***** Running Evaluation *****
[INFO|trainer.py:2326] 2022-06-09 15:44:28,112 >>   Num examples = 338
[INFO|trainer.py:2329] 2022-06-09 15:44:28,112 >>   Batch size = 10
 20%|██████████████████                                                                        | 230/1150 [05:09<20:59,  1.37s/it][INFO|trainer.py:528] 2022-06-09 15:46:59,967 >> The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: not_valid_for_eval, length.
[INFO|trainer.py:2324] 2022-06-09 15:46:59,974 >> ***** Running Evaluation *****
[INFO|trainer.py:2326] 2022-06-09 15:46:59,993 >>   Num examples = 338
[INFO|trainer.py:2329] 2022-06-09 15:46:59,993 >>   Batch size = 10
 30%|███████████████████████████                                                               | 345/1150 [07:42<18:14,  1.36s/it][INFO|trainer.py:528] 2022-06-09 15:49:33,209 >> The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: not_valid_for_eval, length.
[INFO|trainer.py:2324] 2022-06-09 15:49:33,221 >> ***** Running Evaluation *****
[INFO|trainer.py:2326] 2022-06-09 15:49:33,228 >>   Num examples = 338
[INFO|trainer.py:2329] 2022-06-09 15:49:33,235 >>   Batch size = 10
 40%|████████████████████████████████████                                                      | 460/1150 [10:15<15:57,  1.39s/it][INFO|trainer.py:528] 2022-06-09 15:52:05,973 >> The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: not_valid_for_eval, length.
[INFO|trainer.py:2324] 2022-06-09 15:52:05,984 >> ***** Running Evaluation *****
[INFO|trainer.py:2326] 2022-06-09 15:52:05,991 >>   Num examples = 338
[INFO|trainer.py:2329] 2022-06-09 15:52:05,991 >>   Batch size = 10
 50%|█████████████████████████████████████████████                                             | 575/1150 [12:48<13:08,  1.37s/it][INFO|trainer.py:528] 2022-06-09 15:54:38,875 >> The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: not_valid_for_eval, length.
[INFO|trainer.py:2324] 2022-06-09 15:54:38,885 >> ***** Running Evaluation *****
[INFO|trainer.py:2326] 2022-06-09 15:54:38,898 >>   Num examples = 338
[INFO|trainer.py:2329] 2022-06-09 15:54:38,898 >>   Batch size = 10
 60%|██████████████████████████████████████████████████████                                    | 690/1150 [15:20<10:27,  1.36s/it][INFO|trainer.py:528] 2022-06-09 15:57:11,340 >> The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: not_valid_for_eval, length.
[INFO|trainer.py:2324] 2022-06-09 15:57:11,351 >> ***** Running Evaluation *****
[INFO|trainer.py:2326] 2022-06-09 15:57:11,358 >>   Num examples = 338
[INFO|trainer.py:2329] 2022-06-09 15:57:11,358 >>   Batch size = 10
 70%|██████████████████████████████████████████████████████████████▉                           | 805/1150 [17:53<07:55,  1.38s/it][INFO|trainer.py:528] 2022-06-09 15:59:43,813 >> The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: not_valid_for_eval, length.
[INFO|trainer.py:2324] 2022-06-09 15:59:43,817 >> ***** Running Evaluation *****
[INFO|trainer.py:2326] 2022-06-09 15:59:43,823 >>   Num examples = 338
[INFO|trainer.py:2329] 2022-06-09 15:59:43,823 >>   Batch size = 10
 80%|████████████████████████████████████████████████████████████████████████                  | 920/1150 [20:26<05:16,  1.37s/it][INFO|trainer.py:528] 2022-06-09 16:02:16,934 >> The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: not_valid_for_eval, length.
[INFO|trainer.py:2324] 2022-06-09 16:02:16,937 >> ***** Running Evaluation *****
[INFO|trainer.py:2326] 2022-06-09 16:02:16,951 >>   Num examples = 338
[INFO|trainer.py:2329] 2022-06-09 16:02:16,951 >>   Batch size = 10
 90%|████████████████████████████████████████████████████████████████████████████████         | 1035/1150 [22:58<02:36,  1.36s/it][INFO|trainer.py:528] 2022-06-09 16:04:49,334 >> The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: not_valid_for_eval, length.
[INFO|trainer.py:2324] 2022-06-09 16:04:49,345 >> ***** Running Evaluation *****
[INFO|trainer.py:2326] 2022-06-09 16:04:49,359 >>   Num examples = 338
[INFO|trainer.py:2329] 2022-06-09 16:04:49,359 >>   Batch size = 10
100%|█████████████████████████████████████████████████████████████████████████████████████████| 1150/1150 [25:31<00:00,  1.34s/it][INFO|trainer.py:528] 2022-06-09 16:07:21,629 >> The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: not_valid_for_eval, length.
[INFO|trainer.py:2324] 2022-06-09 16:07:21,634 >> ***** Running Evaluation *****
[INFO|trainer.py:2326] 2022-06-09 16:07:21,655 >>   Num examples = 338
[INFO|trainer.py:2329] 2022-06-09 16:07:21,655 >>   Batch size = 10
100%|█████████████████████████████████████████████████████████████████████████████████████████| 1150/1150 [25:33<00:00,  1.34s/it][INFO|trainer.py:1507] 2022-06-09 16:07:23,555 >>
Training completed. Do not forget to share your model on huggingface.co/models =)
100%|█████████████████████████████████████████████████████████████████████████████████████████| 1150/1150 [25:33<00:00,  1.33s/it]
[INFO|trainer.py:2072] 2022-06-09 16:07:23,588 >> Saving model checkpoint to /disk/nfs/ostrom/s1970716/scrolls/baselines/outputs/facebook-bart-base_256_1_0.0002_2048_scrolls_summ_screen_fd_future-spite-32
[INFO|configuration_utils.py:391] 2022-06-09 16:07:23,612 >> Configuration saved in /disk/nfs/ostrom/s1970716/scrolls/baselines/outputs/facebook-bart-base_256_1_0.0002_2048_scrolls_summ_screen_fd_future-spite-32/config.json
[INFO|modeling_utils.py:1001] 2022-06-09 16:07:33,960 >> Model weights saved in /disk/nfs/ostrom/s1970716/scrolls/baselines/outputs/facebook-bart-base_256_1_0.0002_2048_scrolls_summ_screen_fd_future-spite-32/pytorch_model.bin
[INFO|tokenization_utils_base.py:2020] 2022-06-09 16:07:33,971 >> tokenizer config file saved in /disk/nfs/ostrom/s1970716/scrolls/baselines/outputs/facebook-bart-base_256_1_0.0002_2048_scrolls_summ_screen_fd_future-spite-32/tokenizer_config.json
[INFO|tokenization_utils_base.py:2026] 2022-06-09 16:07:33,973 >> Special tokens file saved in /disk/nfs/ostrom/s1970716/scrolls/baselines/outputs/facebook-bart-base_256_1_0.0002_2048_scrolls_summ_screen_fd_future-spite-32/special_tokens_map.json
2022-06-09 16:07:34 | INFO | __main__ | *** Evaluate ***
[INFO|trainer.py:528] 2022-06-09 16:07:34,699 >> The following columns in the evaluation set  don't have a corresponding argument in `BartForConditionalGeneration.forward` and have been ignored: not_valid_for_eval, length.
[INFO|trainer.py:2324] 2022-06-09 16:07:34,702 >> ***** Running Evaluation *****
[INFO|trainer.py:2326] 2022-06-09 16:07:34,702 >>   Num examples = 338
[INFO|trainer.py:2329] 2022-06-09 16:07:34,703 >>   Batch size = 10
100%|███████████████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:01<00:00,  5.39it/s]